@article{Settgast:2017,
  author = {Settgast, Randolph R. and Fu, Pengcheng and Walsh, Stuart D.C. and White, Joshua A. and Annavarapu, Chandrasekhar and Ryerson, Frederick J.},
  title = {A fully coupled method for massively parallel simulation of hydraulically driven fractures in 3-dimensions},
  journal = {International Journal for Numerical and Analytical Methods in Geomechanics},
  volume = {41},
  number = {5},
  pages = {627-653},
  year = {2017},
  doi = {10.1002/nag.2557}
}

@Manual{libgeos,
  title = {{GEOS} computational geometry library},
  author = {{GEOS contributors}},
  organization = {Open Source Geospatial Foundation},
  year = {2021},
  url = {https://libgeos.org/},
  doi = {10.5281/zenodo.11396894}
}

@InProceedings{Beckingsale:2019,
  author={Beckingsale, David A. and Burmark, Jason and Hornung, Rich and Jones, Holger and Killian, William and Kunen, Adam J. and Pearce, Olga and Robinson, Peter and Ryujin, Brian S. and Scogland, Thomas R. W.},
  booktitle={2019 IEEE/ACM International Workshop on Performance, Portability and Productivity in HPC (P3HPC)}, 
  title={RAJA: Portable Performance for Large-Scale Scientific Applications}, 
  pages={71-81},
  year={2019},
  doi={10.1109/P3HPC49587.2019.00012}}

@misc{CHAI:2023,
  title = {CHAI},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/LLNL/chai}
}

@article{Beckingsale:2020,
  author={Beckingsale, D. A. and McFadden, M. J. and Dahm, J. P. S. and Pankajakshan, R. and Hornung, R. D.},
  title={Umpire: Application-focused management and coordination of complex hierarchical memory}, 
  journal={IBM Journal of Research and Development}, 
  volume={64},
  number={3/4},
  pages={15:1-15:10},
  year={2020},
  doi={10.1147/JRD.2019.2954403}
}

@InProceedings{hypre,
  author = {Falgout, R. D.  and  Yang, U. M.},
  title = {\textit{hypre}: a Library of High Performance Preconditioners},
  booktitle = {Lecture Notes in Computer Science},
  pages = {632--641},
  year = {2002},
  doi={10.1007/3-540-47789-6_66}
}

@Misc{petsc-web-page,
  author = {Satish Balay and Shrirang Abhyankar and Mark~F. Adams and Steven Benson and Jed
           Brown and Peter Brune and Kris Buschelman and Emil~M. Constantinescu and Lisandro
           Dalcin and Alp Dener and Victor Eijkhout and Jacob Faibussowitsch and William~D.
           Gropp and V\'{a}clav Hapla and Tobin Isaac and Pierre Jolivet and Dmitry Karpeev
           and Dinesh Kaushik and Matthew~G. Knepley and Fande Kong and Scott Kruger and
           Dave~A. May and Lois Curfman McInnes and Richard Tran Mills and Lawrence Mitchell
           and Todd Munson and Jose~E. Roman and Karl Rupp and Patrick Sanan and Jason Sarich
           and Barry~F. Smith and Stefano Zampini and Hong Zhang and Hong Zhang and Junchao
           Zhang},
  title  = {{PETS}c {W}eb page},
  url    = {https://petsc.org/},
  year   = {2024}
}

@article{ Her_etal05,
  title={{An overview of the Trilinos project}},
  author={Heroux, M. A. and Bartlett, R. A. and Howle, V. E. and Hoekstra, R. J. and Hu, J. J. and Kolda, T. G. and Lehoucq, R. B. and Long, K. R. and Pawlowski, R. P. and Phipps, E. T. and Salinger, A. G. and Thornquist, H. K. and Tuminaro, R. S. and Willenbring, J. M. and Williams, A. and Stanley, K. S.},
  journal={ACM Trans. Math. Softw.},
  volume={31},
  number={3},
  pages={397--423},
  year={2005},
  doi={10.1145/1089014.1089021}
}


@article{BUI:2020,
  author = {Bui, Quan M. and Osei-Kuffuor, Daniel and Castelletto, Nicola and White, Joshua A.},
  title = {A Scalable Multigrid Reduction Framework for Multiphase Poromechanics of Heterogeneous Media},
  journal = {SIAM Journal on Scientific Computing},
  volume = {42},
  number = {2},
  pages = {B379-B396},
  year = {2020},
  doi = {10.1137/19M1256117},
}

@article{BUI:2021114111,
  author = {Quan M. Bui and François P. Hamon and Nicola Castelletto and Daniel Osei-Kuffuor and Randolph R. Settgast and Joshua A. White},
  title = {Multigrid reduction preconditioning framework for coupled processes in porous and fractured media},
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {387},
  pages = {114111},
  year = {2021},
  doi = {10.1016/j.cma.2021.114111}
}

@book{ IPCC_2023, 
  author={{Intergovernmental Panel on Climate Change IPCC}},
  title={{Climate Change 2022 - Mitigation of Climate Change: Working Group III Contribution to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change}}, 
  publisher={Cambridge University Press}, 
  place={Cambridge}, 
  year={2023},
  doi = {10.1017/9781009157926}
}

@misc{GEOS_RTD,
    title = {GEOS Documentation},
    year = {2024},
    url = {https://geosx-geosx.readthedocs-hosted.com/en/latest/},
}

@misc{PerformancePortablityOrg,
    title = {Performance Portability Org},
    url = {https://performanceportability.org}
}

@article{Nordbotten2024,
abstract = {This article contains the description of, and call for participation in, the 11th Society of Petroleum Engineers Comparative Solution Project (the 11th SPE CSP, https://spe.org/csp). It is motivated by the simulation challenges associated with CO2 storage operations in geological settings of realistic complexity. The 11th SPE CSP contains three versions: Version 11A is a 2D geometry at the laboratory scale, inspired by a recent CO2 storage forecasting and validation study. For Version 11B, the 2D geometry and operational conditions from 11A are rescaled to field conditions characteristic of the Norwegian Continental Shelf. Finally, for Version 11C, the geometry of Version 11B is extruded to a full 3D field model. The CSP has a two-year timeline, being launched at the 2023 SPE Reservoir Simulation Conference and culminating at the 2025 SPE Reservoir Simulation Conference. A community effort is run in parallel to develop utility scripts and input files for common simulators to lower the threshold of participation; see the link to supplementary material on the CSP website. At the time of writing, complete input decks for one simulator are already ready for all three versions.},
author = {Nordbotten, Jan M. and Ferno, Martin A. and Flemisch, Bernd and Kovscek, Anthony R. and Lie, Knut Andreas},
doi = {10.2118/218015-PA},
file = {:Users/settgast1/Documents/Mendeley Desktop/Nordbotten/2024/The 11th Society of Petroleum Engineers Comparative Solution Project Problem Definition/Nordbotten - 2024 - The 11th Society of Petroleum Engineers Comparative Solution Project Problem Definition.pdf:pdf},
issn = {1086055X},
journal = {SPE Journal},
number = {5},
pages = {2507--2524},
title = {{The 11th Society of Petroleum Engineers Comparative Solution Project: Problem Definition}},
volume = {29},
year = {2024}
}

@software{ogs:6.5.2,
  author       = {Naumov, Dmitri and
                  Bilke, Lars and
                  Lehmann, Christoph and
                  Fischer, Thomas and
                  Wang, Wenqing and
                  Silbermann, Christian and
                  Thiedau, Jan and
                  Selzer, Philipp},
  title        = {OpenGeoSys},
  month        = jun,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {6.5.2},
  doi          = {10.5281/zenodo.11652195},
  url          = {https://doi.org/10.5281/zenodo.11652195}
}

@article{Kochetal2020Dumux,
title = "{DuMu\textsuperscript{x} 3 - an open-source simulator for solving flow and transport problems in porous media with a focus on model coupling}",
journal = "Computers \& Mathematics with Applications",
year = "2020",
issn = "0898-1221",
doi = "10.1016/j.camwa.2020.02.012",
author = "Timo Koch and Dennis Gl\"aser and Kilian Weishaupt and Sina Ackermann and Martin Beck and Beatrix Becker and Samuel Burbulla and Holger Class and Edward Coltman and Simon Emmert and Thomas Fetzer and Christoph Gr\"uninger and Katharina Heck and Johannes Hommel and Theresa Kurz and Melanie Lipp and Farid Mohammadi and Samuel Scherrer and Martin Schneider and Gabriele Seitz and Leopold Stadler and Martin Utz and Felix Weinhardt and Bernd Flemisch",
keywords = "Porous media, Multi-phase flow, , Coupled problems, Open-source software, Research software",
abstract = "We present version 3 of the open-source simulator for flow and transport processes in porous media DuMux. DuMux is based on the modular C++ framework Dune (Distributed and Unified Numerics Environment) and is developed as a research code with a focus on modularity and reusability. We describe recent efforts in improving the transparency and efficiency of the development process and community-building, as well as efforts towards quality assurance and reproducible research. In addition to a major redesign of many simulation components in order to facilitate setting up complex simulations in DuMux, version 3 introduces a more consistent abstraction of finite volume schemes. Finally, the new framework for multi-domain simulations is described, and three numerical examples demonstrate its flexibility."
}

@article{RASMUSSEN2021159,
title = {{The Open Porous Media Flow reservoir simulator}},
journal = {Computers & Mathematics with Applications},
volume = {81},
pages = {159-185},
year = {2021},
note = {Development and Application of Open-source Software for Problems with Numerical PDEs},
issn = {0898-1221},
doi = {https://doi.org/10.1016/j.camwa.2020.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0898122120302182},
author = {Atgeirr Flø Rasmussen and Tor Harald Sandve and Kai Bao and Andreas Lauser and Joakim Hove and Bård Skaflestad and Robert Klöfkorn and Markus Blatt and Alf Birger Rustad and Ove Sævareid and Knut-Andreas Lie and Andreas Thune},
abstract = {The Open Porous Media (OPM) initiative is a community effort that encourages open innovation and reproducible research for simulation of porous media processes. OPM coordinates collaborative software development, maintains and distributes open-source software and open data sets, and seeks to ensure that these are available under a free license in a long-term perspective. In this paper, we present OPM Flow, which is a reservoir simulator developed for industrial use, as well as some of the individual components used to make OPM Flow. The descriptions apply to the 2019.10 release of OPM.}
}


@article{Voskov2024, doi = {10.21105/joss.06737}, url = {https://doi.org/10.21105/joss.06737}, year = {2024}, publisher = {The Open Journal}, volume = {9}, number = {99}, pages = {6737}, author = {Denis Voskov and Ilshat Saifullin and Aleksei Novikov and Michiel Wapperom and Luisa Orozco and Gabriel Serrão Seabra and Yuan Chen and Mark Khait and Xiaocong Lyu and Xiaoming Tian and Stephan de Hoop and Artur Palha}, title = {{open Delft Advanced Research Terra Simulator (open-DARTS)}}, journal = {Journal of Open Source Software} }

@inproceedings{frontier,
author = {Atchley, Scott and Zimmer, Christopher and Lange, John and Bernholdt, David and Melesse Vergara, Veronica and Beck, Thomas and Brim, Michael and Budiardja, Reuben and Chandrasekaran, Sunita and Eisenbach, Markus and Evans, Thomas and Ezell, Matthew and Frontiere, Nicholas and Georgiadou, Antigoni and Glenski, Joe and Grete, Philipp and Hamilton, Steven and Holmen, John and Huebl, Axel and Jacobson, Daniel and Joubert, Wayne and Mcmahon, Kim and Merzari, Elia and Moore, Stan and Myers, Andrew and Nichols, Stephen and Oral, Sarp and Papatheodore, Thomas and Perez, Danny and Rogers, David M. and Schneider, Evan and Vay, Jean-Luc and Yeung, P. K.},
title = {Frontier: Exploring Exascale},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3607089},
doi = {10.1145/3581784.3607089},
abstract = {As the US Department of Energy (DOE) computing facilities began deploying petascale systems in 2008, DOE was already setting its sights on exascale. In that year, DARPA published a report on the feasibility of reaching exascale. The report authors identified several key challenges in the pursuit of exascale including power, memory, concurrency, and resiliency. That report informed the DOE's computing strategy for reaching exascale. With the deployment of Oak Ridge National Laboratory's Frontier supercomputer, we have officially entered the exascale era. In this paper, we discuss Frontier's architecture, how it addresses those challenges, and describe some early application results from Oak Ridge Leadership Computing Facility's Center of Excellence and the Exascale Computing Project.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {52},
numpages = {16},
location = {Denver, CO, USA},
series = {SC '23}
}